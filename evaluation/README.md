## Evaluation Workflow 
![entities](https://github.com/LiUSemWeb/OBG-gen/blob/main/figures/evaluation-workflow.png "evaluation workflow")

* For the evaluation, we consider two scenarios: a real application scenario in the materials design domain and a synthetic benchmark scenario bason on [Link√∂ping GraphQL Benchmark](https://github.com/LiUGraphQL/LinGBM) (LinGBM).

### Real Case Evaluation

* An example query is shown below.

* You can find all the 12 queries at [this folder](https://github.com/LiUSemWeb/OBG-gen/tree/main/evaluation/materials_design_domain).

* Query Execution Time (QET) per data size on materials dataset.
![entities](https://github.com/LiUSemWeb/OBG-gen/blob/main/figures/evaluation-md-QETs-per-dataset.png "per-dataset")
* Query Execution Time (QET) per query on materials dataset.
![entities](https://github.com/LiUSemWeb/OBG-gen/blob/main/figures/evaluation-md-QETs-per-query.png "The framework of OBG-gen")

### Synthetic Evaluation

* An example query is shown below.

* You can find all the 12 queries at [this folder](https://github.com/LiUSemWeb/OBG-gen/tree/main/evaluation/university_domain_LinGBM).